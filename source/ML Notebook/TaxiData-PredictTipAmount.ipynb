{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import Libraries \r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.core import Experiment, Datastore, Dataset\r\n",
        "from azureml.core import Model\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn import preprocessing\r\n",
        "import os\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "workspace = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, workspace.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.41.0 to work with mtcist-mlws\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1647192725019
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Data to Datastore\r\n",
        "blob_datastore_name='azblobsdk' # Name of the datastore to workspace\r\n",
        "container_name=os.getenv(\"BLOB_CONTAINER\", \"mtcsynapse\") # Name of Azure blob container\r\n",
        "account_name=os.getenv(\"BLOB_ACCOUNTNAME\", \"mtcsynapse\") # Storage account name\r\n",
        "account_key=os.getenv(\"BLOB_ACCOUNT_KEY\", \"T9HOwGaOZtNJZTmOGcudpr3hND/2h6rlURq2BIqwMIIIu2oHPfURj2PbNYPdNvdDJLaWdD6uzImEUjtlUU0/uw==\") # Storage account access key\r\n",
        "\r\n",
        "blob_datastore = Datastore.register_azure_blob_container(workspace=workspace, \r\n",
        "                                                         datastore_name=blob_datastore_name, \r\n",
        "                                                         container_name=container_name, \r\n",
        "                                                         account_name=account_name,\r\n",
        "                                                         account_key=account_key)\r\n",
        "\r\n",
        "csv_path=[(blob_datastore, './FinanceDemo/dbo.taxidata.csv')]\r\n",
        "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_path)\r\n",
        "df = tab_ds.to_pandas_dataframe()\r\n",
        "#Copy the dataset\r\n",
        "dfb = df.copy()\r\n",
        "#Explore the dataset\r\n",
        "dfb.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   congestion_surcharge                          DOLocationID  extra  \\\n0                   2.5  1C340B97-68C4-45D7-838B-CF2F69D78F19    0.0   \n1                   2.5  1C340B97-68C4-45D7-838B-CF2F69D78F19    0.0   \n2                   2.5  1C340B97-68C4-45D7-838B-CF2F69D78F19    0.0   \n3                   2.5  1C340B97-68C4-45D7-838B-CF2F69D78F19    0.0   \n4                   2.5  1C340B97-68C4-45D7-838B-CF2F69D78F19    0.0   \n\n   fare_amount  improvement_surcharge  mta_tax  passenger_count  payment_type  \\\n0          5.0                    0.3      0.5              1.0           2.0   \n1          5.0                    0.3      0.5              1.0           2.0   \n2          5.0                    0.3      0.5              1.0           2.0   \n3          5.0                    0.3      0.5              1.0           2.0   \n4          5.0                    0.3      0.5              1.0           2.0   \n\n                           PULocationID  RatecodeID store_and_fwd_flag  \\\n0  DD889A14-C004-47B7-8217-1E5DB1A7377C         1.0              False   \n1  DD889A14-C004-47B7-8217-1E5DB1A7377C         1.0              False   \n2  DD889A14-C004-47B7-8217-1E5DB1A7377C         1.0              False   \n3  070B8A4E-8385-412B-B46A-05F381F6863D         1.0              False   \n4  070B8A4E-8385-412B-B46A-05F381F6863D         1.0              False   \n\n   tip_amount  tolls_amount  total_amount tpep_dropoff_datetime  \\\n0         0.0           0.0           8.3   2020-06-17 06:20:34   \n1         0.0           0.0           8.3   2020-06-17 06:20:34   \n2         0.0           0.0           8.3   2020-06-17 06:20:34   \n3         0.0           0.0           8.3   2020-06-17 06:20:34   \n4         0.0           0.0           8.3   2020-06-17 06:20:34   \n\n  tpep_pickup_datetime  trip_distance                              VendorID  \n0  2020-06-17 06:17:04           1.02  4D5C74F3-EB53-4677-8CC1-40DE172232AA  \n1  2020-06-17 06:17:04           1.02  AE0E18EF-99DC-490C-9F30-93FF65776262  \n2  2020-06-17 06:17:04           1.02  BCEA53DA-E187-4958-8EE3-1350B41EE9DC  \n3  2020-06-17 06:17:04           1.02  4D5C74F3-EB53-4677-8CC1-40DE172232AA  \n4  2020-06-17 06:17:04           1.02  AE0E18EF-99DC-490C-9F30-93FF65776262  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>congestion_surcharge</th>\n      <th>DOLocationID</th>\n      <th>extra</th>\n      <th>fare_amount</th>\n      <th>improvement_surcharge</th>\n      <th>mta_tax</th>\n      <th>passenger_count</th>\n      <th>payment_type</th>\n      <th>PULocationID</th>\n      <th>RatecodeID</th>\n      <th>store_and_fwd_flag</th>\n      <th>tip_amount</th>\n      <th>tolls_amount</th>\n      <th>total_amount</th>\n      <th>tpep_dropoff_datetime</th>\n      <th>tpep_pickup_datetime</th>\n      <th>trip_distance</th>\n      <th>VendorID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.5</td>\n      <td>1C340B97-68C4-45D7-838B-CF2F69D78F19</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>DD889A14-C004-47B7-8217-1E5DB1A7377C</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>2020-06-17 06:20:34</td>\n      <td>2020-06-17 06:17:04</td>\n      <td>1.02</td>\n      <td>4D5C74F3-EB53-4677-8CC1-40DE172232AA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.5</td>\n      <td>1C340B97-68C4-45D7-838B-CF2F69D78F19</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>DD889A14-C004-47B7-8217-1E5DB1A7377C</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>2020-06-17 06:20:34</td>\n      <td>2020-06-17 06:17:04</td>\n      <td>1.02</td>\n      <td>AE0E18EF-99DC-490C-9F30-93FF65776262</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.5</td>\n      <td>1C340B97-68C4-45D7-838B-CF2F69D78F19</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>DD889A14-C004-47B7-8217-1E5DB1A7377C</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>2020-06-17 06:20:34</td>\n      <td>2020-06-17 06:17:04</td>\n      <td>1.02</td>\n      <td>BCEA53DA-E187-4958-8EE3-1350B41EE9DC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.5</td>\n      <td>1C340B97-68C4-45D7-838B-CF2F69D78F19</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>070B8A4E-8385-412B-B46A-05F381F6863D</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>2020-06-17 06:20:34</td>\n      <td>2020-06-17 06:17:04</td>\n      <td>1.02</td>\n      <td>4D5C74F3-EB53-4677-8CC1-40DE172232AA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.5</td>\n      <td>1C340B97-68C4-45D7-838B-CF2F69D78F19</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>070B8A4E-8385-412B-B46A-05F381F6863D</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.3</td>\n      <td>2020-06-17 06:20:34</td>\n      <td>2020-06-17 06:17:04</td>\n      <td>1.02</td>\n      <td>AE0E18EF-99DC-490C-9F30-93FF65776262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647192740848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get ready for train\r\n",
        "\r\n",
        "#cleanse data\r\n",
        "df = df.drop_duplicates()\r\n",
        "def impute_missing_for_cats(dataset):\r\n",
        "    for i in dataset.columns:\r\n",
        "        if (dataset[i].isnull().sum()>0):\r\n",
        "            dataset.loc[dataset[i].isnull(),i] = dataset[i].value_counts().index[0]\r\n",
        "    return dataset\r\n",
        "\r\n",
        "df = impute_missing_for_cats(df)\r\n",
        "\r\n",
        "#copy to generate datasets to be used for prediction\r\n",
        "dft = df.copy()\r\n",
        "\r\n",
        "#transform \r\n",
        "#change data types\r\n",
        "dft['tpep_pickup_datetime']  = dft['tpep_pickup_datetime'].astype(str)\r\n",
        "dft['tpep_dropoff_datetime'] = dft['tpep_dropoff_datetime'].astype(str)\r\n",
        "\r\n",
        "#apply label encoder\r\n",
        "le = preprocessing.LabelEncoder()\r\n",
        "df['VendorID']=le.fit_transform(df['VendorID'])\r\n",
        "df['PULocationID']=le.fit_transform(df['PULocationID'])\r\n",
        "df['DOLocationID']=le.fit_transform(df['DOLocationID'])\r\n",
        "df['store_and_fwd_flag']=le.fit_transform(df['store_and_fwd_flag'])\r\n",
        "\r\n",
        "#tip amount should be greater than zero\r\n",
        "df = df.loc[df['tip_amount']>=0,:]\r\n",
        "df['duration'] = (df.tpep_dropoff_datetime-df.tpep_pickup_datetime).dt.total_seconds()/60.0\r\n",
        "\r\n",
        "#extract date and time values \r\n",
        "df['pickup_year'] = df['tpep_pickup_datetime'].dt.year\r\n",
        "df['pickup_month'] = df['tpep_pickup_datetime'].dt.month\r\n",
        "df['pickup_weekday'] = df['tpep_pickup_datetime'].dt.weekday\r\n",
        "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\r\n",
        "df['dropoff_year'] = df['tpep_dropoff_datetime'].dt.year\r\n",
        "df['dropoff_month'] = df['tpep_dropoff_datetime'].dt.month\r\n",
        "df['dropoff_weekday'] = df['tpep_dropoff_datetime'].dt.weekday\r\n",
        "df['dropoff_hour'] = df['tpep_dropoff_datetime'].dt.hour\r\n",
        "\r\n",
        "#drop unneccessary coulumns\r\n",
        "df = df.drop(columns='tpep_pickup_datetime')\r\n",
        "df = df.drop(columns='tpep_dropoff_datetime')\r\n",
        "df = df.loc[df.pickup_year==2020,:]\r\n",
        "df = df.loc[df.dropoff_year==2020,:] \r\n",
        "df = df.drop(columns='pickup_year')\r\n",
        "df = df.drop(columns='dropoff_year')\r\n",
        "df = df.drop(columns='mta_tax')\r\n",
        "df = df.drop(columns='dropoff_hour')\r\n",
        "df = df.drop(columns='dropoff_weekday')\r\n",
        "df = df.drop(columns='dropoff_month')\r\n",
        "df = df.drop(columns='tolls_amount')\r\n",
        "df = df.drop(columns='improvement_surcharge')\r\n",
        "df = df.drop(columns='extra')\r\n",
        "\r\n",
        "#split data set\r\n",
        "def split(dataset):\r\n",
        "    target_col = \"tip_amount\"\r\n",
        "    X = dataset.drop(columns=target_col)\r\n",
        "    y = dataset[target_col]\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n",
        "    return X_train, X_test, y_train, y_test\r\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193000453
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Azure ML experiment in your workspace\r\n",
        "experiment = Experiment(workspace=workspace, name='batch-taxi-data')\r\n",
        "run = experiment.start_logging(snapshot_directory=None)\r\n",
        "print(\"Starting experiment:\", experiment.name)\r\n",
        "\r\n",
        "\r\n",
        "# Prepare X & Y\r\n",
        "#Execute function \r\n",
        "X_train, X_test, y_train, y_test = split(df)\r\n",
        "\r\n",
        "# Train a linear regression tree model\r\n",
        "print('Training a linear regression model')\r\n",
        "reg = LinearRegression()\r\n",
        "reg.fit(X_train,y_train)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# calculate accuracy\r\n",
        "y_pred = reg.predict(X_test)\r\n",
        "\r\n",
        "run.log('R^2=',metrics.explained_variance_score(y_test,y_pred))\r\n",
        "run.log('MAE:',metrics.mean_absolute_error(y_test,y_pred))\r\n",
        "run.log('MSE:',metrics.mean_squared_error(y_test,y_pred))\r\n",
        "run.log('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\r\n",
        "\r\n",
        "print('R^2=',metrics.explained_variance_score(y_test,y_pred))\r\n",
        "print('MAE:',metrics.mean_absolute_error(y_test,y_pred))\r\n",
        "\r\n",
        "# Save the trained model\r\n",
        "\r\n",
        "# Complete the run\r\n",
        "model_file = 'reg.pkl'\r\n",
        "joblib.dump(value=reg, filename=model_file)\r\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\r\n",
        "\r\n",
        "run.complete()\r\n",
        "\r\n",
        "# Register the model\r\n",
        "run.register_model(model_path='outputs/reg.pkl', model_name='reg_model',\r\n",
        "                   tags={'Training context':'Inline Training'},\r\n",
        "                   properties={\"R^2=\": run.get_metrics()[\"R^2=\"], 'MAE:': run.get_metrics()['MAE:']})\r\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting experiment: batch-taxi-data\nTraining a linear regression model\nR^2= 0.8089338839866168\nMAE: 0.5383633262366414\nModel trained and registered.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193070671
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and upload batch data - sample data generated simulating future data to be used for prediction\r\n",
        "from azureml.core import Datastore, Dataset\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "# Import Data\r\n",
        "# Set default data store\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "workspace.set_default_datastore('azblobsdk')\r\n",
        "default_ds = workspace.get_default_datastore()\r\n",
        "\r\n",
        "# Enumerate all datastores, indicating which is the default\r\n",
        "for ds_name in workspace.datastores:\r\n",
        "    print(ds_name, \"- Default =\", ds_name == default_ds.name)                            \r\n",
        "\r\n",
        "\r\n",
        "#df = pd.read_csv('transformed_taxidata.csv')\r\n",
        "dft = dft.drop(columns=[ 'tip_amount'])\r\n",
        "# Get a 100-item sample of the feature columns (not the diabetic label)\r\n",
        "sample = dft.sample(n=100).values\r\n",
        "\r\n",
        "# Create a folder\r\n",
        "batch_folder = './batch-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "# Save each sample as a separate file\r\n",
        "print(\"Saving files...\")\r\n",
        "for i in range(100):\r\n",
        "    fname = str(i+1) + '.csv'\r\n",
        "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\r\n",
        "print(\"files saved!\")\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = workspace.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\r\n",
        "\r\n",
        "# Register a dataset for the input data\r\n",
        "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\r\n",
        "try:\r\n",
        "    batch_data_set = batch_data_set.register(workspace=workspace, \r\n",
        "                                             name='batch-data',\r\n",
        "                                             description='batch data',\r\n",
        "                                             create_new_version=True)\r\n",
        "except Exception as ex:\r\n",
        "    print(ex)\r\n",
        "\r\n",
        "print(\"Done!\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml - Default = False\nazblobsdk - Default = True\nworkspaceworkingdirectory - Default = False\nworkspacefilestore - Default = False\nworkspaceartifactstore - Default = False\nworkspaceblobstore - Default = False\nFolder created!\nSaving files...\nfiles saved!\nUploading files to datastore...\nUploading an estimated of 103 files\nUploading batch-data/.amlignore\nUploaded batch-data/.amlignore, 1 files out of an estimated total of 103\nUploading batch-data/.amlignore.amltmp\nUploaded batch-data/.amlignore.amltmp, 2 files out of an estimated total of 103\nUploading batch-data/1.csv\nUploaded batch-data/1.csv, 3 files out of an estimated total of 103\nUploading batch-data/10.csv\nUploaded batch-data/10.csv, 4 files out of an estimated total of 103\nUploading batch-data/100.csv\nUploaded batch-data/100.csv, 5 files out of an estimated total of 103\nUploading batch-data/11.csv\nUploaded batch-data/11.csv, 6 files out of an estimated total of 103\nUploading batch-data/12.csv\nUploaded batch-data/12.csv, 7 files out of an estimated total of 103\nUploading batch-data/13.csv\nUploaded batch-data/13.csv, 8 files out of an estimated total of 103\nUploading batch-data/14.csv\nUploaded batch-data/14.csv, 9 files out of an estimated total of 103\nUploading batch-data/15.csv\nUploaded batch-data/15.csv, 10 files out of an estimated total of 103\nUploading batch-data/16.csv\nUploaded batch-data/16.csv, 11 files out of an estimated total of 103\nUploading batch-data/17.csv\nUploaded batch-data/17.csv, 12 files out of an estimated total of 103\nUploading batch-data/18.csv\nUploaded batch-data/18.csv, 13 files out of an estimated total of 103\nUploading batch-data/19.csv\nUploaded batch-data/19.csv, 14 files out of an estimated total of 103\nUploading batch-data/2.csv\nUploaded batch-data/2.csv, 15 files out of an estimated total of 103\nUploading batch-data/20.csv\nUploaded batch-data/20.csv, 16 files out of an estimated total of 103\nUploading batch-data/21.csv\nUploaded batch-data/21.csv, 17 files out of an estimated total of 103\nUploading batch-data/22.csv\nUploaded batch-data/22.csv, 18 files out of an estimated total of 103\nUploading batch-data/23.csv\nUploaded batch-data/23.csv, 19 files out of an estimated total of 103\nUploading batch-data/24.csv\nUploaded batch-data/24.csv, 20 files out of an estimated total of 103\nUploading batch-data/25.csv\nUploaded batch-data/25.csv, 21 files out of an estimated total of 103\nUploading batch-data/26.csv\nUploaded batch-data/26.csv, 22 files out of an estimated total of 103\nUploading batch-data/27.csv\nUploaded batch-data/27.csv, 23 files out of an estimated total of 103\nUploading batch-data/28.csv\nUploaded batch-data/28.csv, 24 files out of an estimated total of 103\nUploading batch-data/29.csv\nUploaded batch-data/29.csv, 25 files out of an estimated total of 103\nUploading batch-data/3.csv\nUploaded batch-data/3.csv, 26 files out of an estimated total of 103\nUploading batch-data/30.csv\nUploaded batch-data/30.csv, 27 files out of an estimated total of 103\nUploading batch-data/31.csv\nUploaded batch-data/31.csv, 28 files out of an estimated total of 103\nUploading batch-data/32.csv\nUploaded batch-data/32.csv, 29 files out of an estimated total of 103\nUploading batch-data/33.csv\nUploaded batch-data/33.csv, 30 files out of an estimated total of 103\nUploading batch-data/34.csv\nUploaded batch-data/34.csv, 31 files out of an estimated total of 103\nUploading batch-data/35.csv\nUploaded batch-data/35.csv, 32 files out of an estimated total of 103\nUploading batch-data/36.csv\nUploaded batch-data/36.csv, 33 files out of an estimated total of 103\nUploading batch-data/37.csv\nUploaded batch-data/37.csv, 34 files out of an estimated total of 103\nUploading batch-data/38.csv\nUploaded batch-data/38.csv, 35 files out of an estimated total of 103\nUploading batch-data/39.csv\nUploaded batch-data/39.csv, 36 files out of an estimated total of 103\nUploading batch-data/4.csv\nUploaded batch-data/4.csv, 37 files out of an estimated total of 103\nUploading batch-data/40.csv\nUploaded batch-data/40.csv, 38 files out of an estimated total of 103\nUploading batch-data/41.csv\nUploaded batch-data/41.csv, 39 files out of an estimated total of 103\nUploading batch-data/42.csv\nUploaded batch-data/42.csv, 40 files out of an estimated total of 103\nUploading batch-data/43.csv\nUploaded batch-data/43.csv, 41 files out of an estimated total of 103\nUploading batch-data/44.csv\nUploaded batch-data/44.csv, 42 files out of an estimated total of 103\nUploading batch-data/45.csv\nUploaded batch-data/45.csv, 43 files out of an estimated total of 103\nUploading batch-data/46.csv\nUploaded batch-data/46.csv, 44 files out of an estimated total of 103\nUploading batch-data/47.csv\nUploaded batch-data/47.csv, 45 files out of an estimated total of 103\nUploading batch-data/48.csv\nUploaded batch-data/48.csv, 46 files out of an estimated total of 103\nUploading batch-data/49.csv\nUploaded batch-data/49.csv, 47 files out of an estimated total of 103\nUploading batch-data/5.csv\nUploaded batch-data/5.csv, 48 files out of an estimated total of 103\nUploading batch-data/50.csv\nUploaded batch-data/50.csv, 49 files out of an estimated total of 103\nUploading batch-data/51.csv\nUploaded batch-data/51.csv, 50 files out of an estimated total of 103\nUploading batch-data/52.csv\nUploaded batch-data/52.csv, 51 files out of an estimated total of 103\nUploading batch-data/53.csv\nUploaded batch-data/53.csv, 52 files out of an estimated total of 103\nUploading batch-data/54.csv\nUploaded batch-data/54.csv, 53 files out of an estimated total of 103\nUploading batch-data/55.csv\nUploaded batch-data/55.csv, 54 files out of an estimated total of 103\nUploading batch-data/56.csv\nUploaded batch-data/56.csv, 55 files out of an estimated total of 103\nUploading batch-data/57.csv\nUploaded batch-data/57.csv, 56 files out of an estimated total of 103\nUploading batch-data/58.csv\nUploaded batch-data/58.csv, 57 files out of an estimated total of 103\nUploading batch-data/59.csv\nUploaded batch-data/59.csv, 58 files out of an estimated total of 103\nUploading batch-data/6.csv\nUploaded batch-data/6.csv, 59 files out of an estimated total of 103\nUploading batch-data/60.csv\nUploaded batch-data/60.csv, 60 files out of an estimated total of 103\nUploading batch-data/61.csv\nUploaded batch-data/61.csv, 61 files out of an estimated total of 103\nUploading batch-data/62.csv\nUploaded batch-data/62.csv, 62 files out of an estimated total of 103\nUploading batch-data/63.csv\nUploaded batch-data/63.csv, 63 files out of an estimated total of 103\nUploading batch-data/64.csv\nUploaded batch-data/64.csv, 64 files out of an estimated total of 103\nUploading batch-data/65.csv\nUploaded batch-data/65.csv, 65 files out of an estimated total of 103\nUploading batch-data/66.csv\nUploaded batch-data/66.csv, 66 files out of an estimated total of 103\nUploading batch-data/67.csv\nUploaded batch-data/67.csv, 67 files out of an estimated total of 103\nUploading batch-data/68.csv\nUploaded batch-data/68.csv, 68 files out of an estimated total of 103\nUploading batch-data/69.csv\nUploaded batch-data/69.csv, 69 files out of an estimated total of 103\nUploading batch-data/7.csv\nUploaded batch-data/7.csv, 70 files out of an estimated total of 103\nUploading batch-data/70.csv\nUploaded batch-data/70.csv, 71 files out of an estimated total of 103\nUploading batch-data/71.csv\nUploaded batch-data/71.csv, 72 files out of an estimated total of 103\nUploading batch-data/72.csv\nUploaded batch-data/72.csv, 73 files out of an estimated total of 103\nUploading batch-data/73.csv\nUploaded batch-data/73.csv, 74 files out of an estimated total of 103\nUploading batch-data/74.csv\nUploaded batch-data/74.csv, 75 files out of an estimated total of 103\nUploading batch-data/75.csv\nUploaded batch-data/75.csv, 76 files out of an estimated total of 103\nUploading batch-data/76.csv\nUploaded batch-data/76.csv, 77 files out of an estimated total of 103\nUploading batch-data/77.csv\nUploaded batch-data/77.csv, 78 files out of an estimated total of 103\nUploading batch-data/78.csv\nUploaded batch-data/78.csv, 79 files out of an estimated total of 103\nUploading batch-data/79.csv\nUploaded batch-data/79.csv, 80 files out of an estimated total of 103\nUploading batch-data/8.csv\nUploaded batch-data/8.csv, 81 files out of an estimated total of 103\nUploading batch-data/80.csv\nUploaded batch-data/80.csv, 82 files out of an estimated total of 103\nUploading batch-data/81.csv\nUploaded batch-data/81.csv, 83 files out of an estimated total of 103\nUploading batch-data/82.csv\nUploaded batch-data/82.csv, 84 files out of an estimated total of 103\nUploading batch-data/83.csv\nUploaded batch-data/83.csv, 85 files out of an estimated total of 103\nUploading batch-data/84.csv\nUploaded batch-data/84.csv, 86 files out of an estimated total of 103\nUploading batch-data/85.csv\nUploaded batch-data/85.csv, 87 files out of an estimated total of 103\nUploading batch-data/86.csv\nUploaded batch-data/86.csv, 88 files out of an estimated total of 103\nUploading batch-data/87.csv\nUploaded batch-data/87.csv, 89 files out of an estimated total of 103\nUploading batch-data/88.csv\nUploaded batch-data/88.csv, 90 files out of an estimated total of 103\nUploading batch-data/89.csv\nUploaded batch-data/89.csv, 91 files out of an estimated total of 103\nUploading batch-data/9.csv\nUploaded batch-data/9.csv, 92 files out of an estimated total of 103\nUploading batch-data/90.csv\nUploaded batch-data/90.csv, 93 files out of an estimated total of 103\nUploading batch-data/91.csv\nUploaded batch-data/91.csv, 94 files out of an estimated total of 103\nUploading batch-data/92.csv\nUploaded batch-data/92.csv, 95 files out of an estimated total of 103\nUploading batch-data/93.csv\nUploaded batch-data/93.csv, 96 files out of an estimated total of 103\nUploading batch-data/94.csv\nUploaded batch-data/94.csv, 97 files out of an estimated total of 103\nUploading batch-data/95.csv\nUploaded batch-data/95.csv, 98 files out of an estimated total of 103\nUploading batch-data/96.csv\nUploaded batch-data/96.csv, 99 files out of an estimated total of 103\nUploading batch-data/97.csv\nUploaded batch-data/97.csv, 100 files out of an estimated total of 103\nUploading batch-data/98.csv\nUploaded batch-data/98.csv, 101 files out of an estimated total of 103\nUploading batch-data/99.csv\nUploaded batch-data/99.csv, 102 files out of an estimated total of 103\nUploading batch-data/final.csv\nUploaded batch-data/final.csv, 103 files out of an estimated total of 103\nUploaded 103 files\nDone!\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193086788
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create compute target for inference if it is not created \r\n",
        "from azureml.core import Workspace\r\n",
        "workspace = Workspace.from_config()\r\n",
        "# Create Compute\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"your-compute-cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    inference_cluster = ComputeTarget(workspace=workspace, name=cluster_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        inference_cluster = ComputeTarget.create(workspace, cluster_name, compute_config)\r\n",
        "        inference_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193087918
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "import os\r\n",
        "# Create a folder for the experiment files\r\n",
        "experiment_folder = 'batch_pipeline'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "batch_pipeline\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193088107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "%%writefile $experiment_folder/batch_taxi.py\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from azureml.core import Model\r\n",
        "import joblib\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "def init():\r\n",
        "    # Runs when the pipeline step is initialized\r\n",
        "    global model\r\n",
        "\r\n",
        "    # load the model\r\n",
        "    model_path = Model.get_model_path('reg_model')\r\n",
        "    model = joblib.load(model_path)\r\n",
        "\r\n",
        "\r\n",
        "def run(mini_batch):\r\n",
        "    # This runs for each batch\r\n",
        "    resultList = []\r\n",
        "\r\n",
        "    # process each file in the batch\r\n",
        "    for f in mini_batch:\r\n",
        "        # Read the comma-delimited data into an array\r\n",
        "        le = preprocessing.LabelEncoder()\r\n",
        "        data=pd.read_csv(f, delimiter=',', header = None)\r\n",
        "        data.columns = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count',\r\n",
        "               'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'payment_type',\r\n",
        "               'fare_amount', 'extra', 'mta_tax', 'tolls_amount',\r\n",
        "               'improvement_surcharge', 'total_amount', 'congestion_surcharge',\r\n",
        "               'VendorID', 'PULocationID', 'DOLocationID']\r\n",
        "        data['tpep_pickup_datetime']  = pd.to_datetime(data['tpep_pickup_datetime'])\r\n",
        "        data['tpep_dropoff_datetime'] = pd.to_datetime(data['tpep_dropoff_datetime']) \r\n",
        "        data['VendorID']=le.fit_transform(data['VendorID'])\r\n",
        "        data['PULocationID']=le.fit_transform(data['PULocationID'])\r\n",
        "        data['DOLocationID']=le.fit_transform(data['DOLocationID'])\r\n",
        "        data['store_and_fwd_flag']=le.fit_transform(data['store_and_fwd_flag'])\r\n",
        "        data['duration'] = (data.tpep_dropoff_datetime-data.tpep_pickup_datetime).dt.total_seconds()/60.0\r\n",
        "        data['pickup_year'] = data['tpep_pickup_datetime'].dt.year\r\n",
        "        data['pickup_month'] = data['tpep_pickup_datetime'].dt.month\r\n",
        "        data['pickup_weekday'] = data['tpep_pickup_datetime'].dt.weekday\r\n",
        "        data['pickup_hour'] = data['tpep_pickup_datetime'].dt.hour\r\n",
        "        data['dropoff_year'] = data['tpep_dropoff_datetime'].dt.year\r\n",
        "        data['dropoff_month'] = data['tpep_dropoff_datetime'].dt.month\r\n",
        "        data['dropoff_weekday'] = data['tpep_dropoff_datetime'].dt.weekday\r\n",
        "        data['dropoff_hour'] = data['tpep_dropoff_datetime'].dt.hour\r\n",
        "        data = data.drop(columns='tpep_pickup_datetime')\r\n",
        "        data = data.drop(columns='tpep_dropoff_datetime')\r\n",
        "        data = data.loc[data.pickup_year==2020,:]\r\n",
        "        data = data.loc[data.dropoff_year==2020,:] \r\n",
        "        data = data.drop(columns='pickup_year')\r\n",
        "        data = data.drop(columns='dropoff_year')\r\n",
        "        data = data.drop(columns='mta_tax')\r\n",
        "        data = data.drop(columns='dropoff_hour')\r\n",
        "        data = data.drop(columns='dropoff_weekday')\r\n",
        "        data = data.drop(columns='dropoff_month')\r\n",
        "        data = data.drop(columns='tolls_amount')\r\n",
        "        data = data.drop(columns='improvement_surcharge')\r\n",
        "        data = data.drop(columns='extra')\r\n",
        "        data = data.values.flatten()\r\n",
        "        #dataReshape into a 2-dimensional array for prediction (model expects multiple items)\r\n",
        "        prediction = model.predict(data.reshape(1, -1))\r\n",
        "        # Append prediction to results\r\n",
        "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\r\n",
        "    return resultList"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting batch_pipeline/batch_taxi.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/batch_environment.yml\r\n",
        "name: batch_environment\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults\r\n",
        "  - pandas"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting batch_pipeline/batch_environment.yml\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647190457235
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\r\n",
        "\r\n",
        "# Create an Environment for the experiment\r\n",
        "batch_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/batch_environment.yml\")\r\n",
        "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\r\n",
        "print('Configuration ready.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Configuration ready.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193163948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "output_dir = OutputFileDatasetConfig(name='inferences')\r\n",
        "\r\n",
        "parallel_run_config = ParallelRunConfig(\r\n",
        "    source_directory=experiment_folder,\r\n",
        "    entry_script=\"batch_taxi.py\",\r\n",
        "    mini_batch_size=\"1\",\r\n",
        "    error_threshold=10,\r\n",
        "    output_action=\"append_row\",\r\n",
        "    environment=batch_env,\r\n",
        "    compute_target=inference_cluster,\r\n",
        "    node_count=2)\r\n",
        "\r\n",
        "parallelrun_step = ParallelRunStep(\r\n",
        "    name='batch-score-taxi',\r\n",
        "    parallel_run_config=parallel_run_config,\r\n",
        "    inputs=[batch_data_set.as_named_input('taxi_batch')],\r\n",
        "    output=output_dir,\r\n",
        "    arguments=[],\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "print('Steps defined')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Steps defined\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193186599
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "\r\n",
        "pipeline = Pipeline(workspace=workspace, steps=[parallelrun_step])\r\n",
        "pipeline_run = Experiment(workspace, 'mslearn-taxi-batch').submit(pipeline)\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step batch-score-taxi [6cd1ce3d][6bc4b7ce-9654-4d78-aca2-f89f9eb293d3], (This step is eligible to reuse a previous run's output)\nSubmitted PipelineRun 927696a7-e7fe-4566-a8b2-277ffb65b83d\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/927696a7-e7fe-4566-a8b2-277ffb65b83d?wsid=/subscriptions/eeff915b-797e-4af4-b406-92c56702f072/resourcegroups/mtcsynapse/workspaces/mtcist-mlws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRunId: 927696a7-e7fe-4566-a8b2-277ffb65b83d\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/927696a7-e7fe-4566-a8b2-277ffb65b83d?wsid=/subscriptions/eeff915b-797e-4af4-b406-92c56702f072/resourcegroups/mtcsynapse/workspaces/mtcist-mlws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: e9064c43-5fa0-4827-8058-44669fceaff6\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/e9064c43-5fa0-4827-8058-44669fceaff6?wsid=/subscriptions/eeff915b-797e-4af4-b406-92c56702f072/resourcegroups/mtcsynapse/workspaces/mtcist-mlws&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nStepRun( batch-score-taxi ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_0acd56ab0118bc184c471018f4e9812b791429aaa724687d95b1022c663b6466_d.txt\n========================================================================================================================\n2022-06-21T07:17:06Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=20808 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2022-06-21T07:17:06Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/mounts/workspaceblobstore -- stdout/stderr: \n2022-06-21T07:17:06Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-06-21T07:17:06Z Starting output-watcher...\n2022-06-21T07:17:06Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2022-06-21T07:17:06Z Executing 'Copy ACR Details file' on 10.0.0.7\n2022-06-21T07:17:06Z Executing 'Copy ACR Details file' on 10.0.0.5\n2022-06-21T07:17:06Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n>>>   \n>>>   \n2022-06-21T07:17:07Z Copy ACR Details file succeeded on 10.0.0.7. Output: \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a\nDigest: sha256:827f6aea3b77adba06a985afe197787070432a1aaee0e5b7ae3fb65a90c602e3\nStatus: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\nviennaglobal.azurecr.io/azureml/azureml_25b35829bfd2d2e3474bad79eb0e0d5a:latest\n2022-06-21T07:17:07Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2022-06-21T07:17:07Z Check if container e9064c43-5fa0-4827-8058-44669fceaff6_DataSidecar already exist exited with 0, \n\n6fd4f7174cd0dbcb59670bf37ab43c25a98e9d09d19a6e36418e4832098efcc3\n2022-06-21T07:17:07Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2022-06-21T07:17:07Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-31df09b84e111e084161ca00de462f30-dc834fedd124f61d-01 -sshRequired=false] \n2022/06/21 07:17:08 Didn't get JobInfoJson from env, now read from file\n2022/06/21 07:17:08 Suceeded read JobInfoJson from file\n2022/06/21 07:17:08 Starting App Insight Logger for task:  containerSetup\n2022/06/21 07:17:08 Version: 3.0.01978.0001 Branch: 20220602.1 Commit: 84857b2\n2022/06/21 07:17:08 Entered ContainerSetupTask - Preparing infiniband\n2022/06/21 07:17:08 Starting infiniband setup\n2022/06/21 07:17:08 Python Version found is Python 3.7.9\n\n2022/06/21 07:17:08 Returning Python Version as 3.7\n2022/06/21 07:17:08 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/06/21 07:17:08 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022-06-21T07:17:08Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-20.04\n2022/06/21 07:17:08 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2022/06/21 07:17:08 Not setting up Infiniband in Container\n2022/06/21 07:17:08 Not setting up Infiniband in Container\n2022-06-21T07:17:08Z Not setting up Infiniband in Container\n2022/06/21 07:17:08 Python Version found is Python 3.7.9\n\n2022/06/21 07:17:08 Returning Python Version as 3.7\n2022/06/21 07:17:08 sshd inside container not required for job, skipping setup.\n2022/06/21 07:17:08 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2022/06/21 07:17:08 App Insight Client has already been closed\n2022/06/21 07:17:08 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2022-06-21T07:17:08Z Starting docker container succeeded.\n2022-06-21T07:17:08Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n\nStreaming azureml-logs/65_job_prep-tvmps_0acd56ab0118bc184c471018f4e9812b791429aaa724687d95b1022c663b6466_d.txt\n===============================================================================================================\n[2022-06-21T07:17:10.178828] Entering job preparation.\n[2022-06-21T07:17:10.827108] Starting job preparation.\n[2022-06-21T07:17:10.827185] Extracting the control code.\n[2022-06-21T07:17:10.827969] Starting extract_project.\n[2022-06-21T07:17:10.828060] Starting to extract zip file.\n[2022-06-21T07:17:10.847804] Finished extracting zip file.\n[2022-06-21T07:17:10.851959] Using urllib.request Python 3.0 or later\n[2022-06-21T07:17:10.852098] Start fetching snapshots.\n[2022-06-21T07:17:10.852303] Start fetching snapshot.\nStarting the daemon thread to refresh tokens in background for process with pid = 51\n[2022-06-21T07:17:11.327764] Finished fetching snapshot.\n[2022-06-21T07:17:11.327819] Start fetching snapshot.\n[2022-06-21T07:17:20.466685] Finished fetching snapshot.\n[2022-06-21T07:17:20.466730] Finished fetching snapshots.\n[2022-06-21T07:17:20.466743] Finished extract_project.\n[2022-06-21T07:17:20.466828] Finished fetching and extracting the control code.\n[2022-06-21T07:17:20.474887] Start run_history_prep.\n[2022-06-21T07:17:20.484580] Job preparation is complete.\n[2022-06-21T07:17:20.484962] Entering Data Context Managers in Sidecar\n[2022-06-21T07:17:20.486718] Running Sidecar prep cmd...\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-06-21T07:17:20.955387] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/azureml/e9064c43-5fa0-4827-8058-44669fceaff6\n[2022-06-21T07:17:20.956372] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n[2022-06-21T07:17:21.136] Enter __enter__ of DatasetContextManager\n[2022-06-21T07:17:21.137] SDK version: azureml-core==1.41.0.post1 azureml-dataprep==3.1.2. Session id: b42ee313-65e9-4542-9165-bc34a514ae3e. Run id: e9064c43-5fa0-4827-8058-44669fceaff6.\n[2022-06-21T07:17:21.137] Processing 'taxi_batch'.\n[2022-06-21T07:17:21.137] Mode: 'mount'.\n[2022-06-21T07:17:21.137] Path on compute is specified: 'False'.\n[2022-06-21T07:17:21.137] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: taxi_batch\n[2022-06-21T07:17:23.898] Processing dataset FileDataset\n{\n  \"source\": [\n    \"('azblobsdk', 'batch-data/')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\"\n  ],\n  \"registration\": {\n    \"id\": \"431472b7-d780-41ca-94ec-2c3d4393106d\",\n    \"name\": \"batch-data\",\n    \"version\": 3,\n    \"description\": \"batch data\",\n    \"workspace\": \"Workspace.create(name='mtcist-mlws', subscription_id='eeff915b-797e-4af4-b406-92c56702f072', resource_group='mtcsynapse')\"\n  }\n}\n[2022-06-21T07:17:24.478] Mounting taxi_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d as folder.\n[2022-06-21T07:17:24.478] Processing 'inferences'.\n[2022-06-21T07:17:24.478] Mode: 'mount'.\n[2022-06-21T07:17:24.478] Path on compute is specified: '/mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk'.\n[2022-06-21T07:17:24.587] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk\n[2022-06-21T07:17:24.587] Output is not a single file\n[2022-06-21T07:17:24.587] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk as folder\n[2022-06-21T07:17:24.966] Mounting taxi_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d.\n[2022-06-21T07:17:25.970] Mounting inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk.\n[2022-06-21T07:17:25.971] Mounted taxi_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d.\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\nAlready registered authentication for run id: e9064c43-5fa0-4827-8058-44669fceaff6\n[2022-06-21T07:17:31.062] Mounted inferences to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk.\n[2022-06-21T07:17:31.089] Exit __enter__ of DatasetContextManager\nuri entered in sidecar: None\nSet Dataset taxi_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d\nSet OutputDataset inferences's target path to /mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk\n[2022-06-21T07:17:31.089951] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n[2022-06-21T07:17:31.922548] Ran Sidecar prep cmd.\n[2022-06-21T07:17:31.923249] Running Context Managers in Sidecar complete.\n\nStreaming azureml-logs/70_driver_log.txt\n========================================\n2022/06/21 07:17:37 Didn't get JobInfoJson from env, now read from file\n2022/06/21 07:17:37 Suceeded read JobInfoJson from file\n2022/06/21 07:17:37 Starting App Insight Logger for task:  runTaskLet\n2022/06/21 07:17:37 Version: 3.0.01978.0001 Branch: 20220602.1 Commit: 84857b2\n2022/06/21 07:17:37 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n2022/06/21 07:17:37 Send process info logs to master server succeeded\n2022/06/21 07:17:37 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/06/21 07:17:37 Send process info logs to master server succeeded\n[2022-06-21T07:17:37.646047] Entering context manager injector.\n[2022-06-21T07:17:38.224251] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.41.0', '--scoring_module_name', 'batch_taxi.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'taxi_batch'])\nScript type = None\n[2022-06-21T07:17:38.228515] Entering Run History Context Manager.\n[2022-06-21T07:17:38.995347] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/azureml/e9064c43-5fa0-4827-8058-44669fceaff6\n[2022-06-21T07:17:38.995394] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.41.0', '--scoring_module_name', 'batch_taxi.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$inferences', '--input_fds_0', 'taxi_batch']\n[2022-06-21T07:17:38.995421] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.41.0', '--scoring_module_name', 'batch_taxi.py', '--mini_batch_size', '1', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk', '--input_fds_0', 'taxi_batch']\n\n2022/06/21 07:17:42 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n\n\n[2022-06-21T07:18:47.880949] The experiment failed. Finalizing run...\nCleaning up all outstanding Run operations, waiting 900.0 seconds\n3 items cleaning up...\nCleanup took 0.28049778938293457 seconds\nazureml_common.parallel_run.exception_info.Exception: Run failed. Below is the error detail:\nEntryScriptException: Entry script error. The number of failed items is 103, which exceeds error threshold 10.\nThe run() function in the entry script had raised exception for 309 times. Please check logs at logs/user/error/* for details.\n  * Error 'Unknown string format: '1C340B97-68C4-45D7-838B-CF2F69D78F19'' occurred 12 times.\n  * Error 'Unknown string format: 'E21E3FDD-F0CF-42DC-954E-63BEE5C7B1BD'' occurred 12 times.\n  * Error 'Length mismatch: Expected axis has 1 elements, new values have 17 elements' occurred 6 times.\n  * Error 'Unknown string format: '6506082F-B1D9-4588-8B5E-12C9DBE73471'' occurred 6 times.\n  * Error 'Unknown string format: '362A6172-3123-4676-BB43-B09F1D07E9F6'' occurred 6 times.\n  * Error 'Unknown string format: 'DEE4104C-ABED-430C-8250-4EFA931E68F4'' occurred 6 times.\n  * Error 'Unknown string format: 'CAF211B7-4C86-4291-8306-DE46ADDE8B06'' occurred 3 times.\n  * Error 'Unknown string format: '3FD8AF85-8C2F-4A03-AC3A-C9C92FBBAA8B'' occurred 3 times.\n  * Error 'Unknown string format: 'D0E5EDC6-C465-48FB-8AE7-767BBE82A017'' occurred 3 times.\n  * Error 'Unknown string format: 'BB9889B2-0A3E-42A0-9B4C-B99841BA605E'' occurred 3 times.\n  * Error 'Unknown string format: 'F7AF6CE1-F3CD-43B4-9A9B-3A2FFD590D98'' occurred 3 times.\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"driver/amlbi_main.py\", line 174, in <module>\n    main()\n  File \"driver/amlbi_main.py\", line 123, in main\n    boot(driver_dir)\n  File \"driver/amlbi_main.py\", line 58, in boot\n    booter.start()\n  File \"driver/azureml_user/parallel_run/boot.py\", line 373, in start\n    self.start_sys_main()\n  File \"driver/azureml_user/parallel_run/boot.py\", line 260, in start_sys_main\n    self.run_sys_main(cmd)\n  File \"driver/azureml_user/parallel_run/boot_simulator.py\", line 40, in run_sys_main\n    self.run(cmd)\n  File \"driver/azureml_user/parallel_run/boot.py\", line 201, in run\n    self.check_run_result(proc=proc, stdout=stdout, stderr=stderr)\n  File \"driver/azureml_user/parallel_run/boot.py\", line 211, in check_run_result\n    BootResult().check_result(stdout)\n  File \"driver/azureml_user/parallel_run/boot_result.py\", line 36, in check_result\n    raise Exception(message) from cause\nException: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n\n[2022-06-21T07:18:48.375055] Finished context manager injector with Exception.\n2022/06/21 07:18:49 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: /mnt/batch/tasks/workitems/f9148442-e9d6-492a-8dd4-87fadbecee31/job-1/e9064c43-5fa0-4827-8_621e85ef-78d5-484f-aea6-97a2dfe7a1ae/wd/runTaskLetTask_error.json\n2022/06/21 07:18:49 Wrapper cmd failed with err: exit status 1\n2022/06/21 07:18:49 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n2022/06/21 07:18:49 Send process info logs to master server succeeded\n2022/06/21 07:18:49 mpirun version string: {\nmpirun (Open MPI) 3.1.2\n\nReport bugs to http://www.open-mpi.org/community/help/\n}\n2022/06/21 07:18:49 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2022/06/21 07:18:49 Process Exiting with Code:  1\n2022/06/21 07:18:49 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n\nStreaming azureml-logs/75_job_post-tvmps_0acd56ab0118bc184c471018f4e9812b791429aaa724687d95b1022c663b6466_d.txt\n===============================================================================================================\n[2022-06-21T07:19:05.619049] Entering job release\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (cryptography 3.2.1 (/opt/miniconda/lib/python3.7/site-packages), Requirement.parse('cryptography>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n[2022-06-21T07:19:06.597477] Starting job release\n[2022-06-21T07:19:06.598010] Logging experiment finalizing status in history service.[2022-06-21T07:19:06.598247] job release stage : upload_datastore starting...\nStarting the daemon thread to refresh tokens in background for process with pid = 287\n[2022-06-21T07:19:06.598718] job release stage : start importing azureml.history._tracking in run_history_release.\n\n[2022-06-21T07:19:06.599230] job release stage : execute_job_release starting...\n[2022-06-21T07:19:06.599750] job release stage : copy_batchai_cached_logs starting...\n[2022-06-21T07:19:06.614356] Entering context manager injector.\n[2022-06-21T07:19:06.617533] job release stage : upload_datastore completed...\n[2022-06-21T07:19:06.613158] job release stage : copy_batchai_cached_logs completed...\n[2022-06-21T07:19:06.735277] job release stage : send_run_telemetry starting...\n[2022-06-21T07:19:06.762654] get vm size and vm region successfully.\n[2022-06-21T07:19:06.773529] get compute meta data successfully.\n[2022-06-21T07:19:06.836353] job release stage : execute_job_release completed...\n[2022-06-21T07:19:07.006179] post artifact meta request successfully.\n[2022-06-21T07:19:07.071189] upload compute record artifact successfully.\n[2022-06-21T07:19:07.071295] job release stage : send_run_telemetry completed...\n[2022-06-21T07:19:07.071574] Running in AzureML-Sidecar, starting to exit user context managers...\n[2022-06-21T07:19:07.071775] Running Sidecar release cmd...\n[2022-06-21T07:19:07.089068] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/azureml/e9064c43-5fa0-4827-8058-44669fceaff6\n[2022-06-21T07:19:07.108] Enter __exit__ of DatasetContextManager\n[2022-06-21T07:19:07.108] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d.\n[2022-06-21T07:19:07.112] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/taxi_batch_431472b7-d780-41ca-94ec-2c3d4393106d.\n[2022-06-21T07:19:07.112] Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk.\n[2022-06-21T07:19:07.136] Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/mtcist-mlws/azureml/e9064c43-5fa0-4827-8058-44669fceaff6/wd/inferences_azblobsdk.\n[2022-06-21T07:19:07.136] Exit __exit__ of DatasetContextManager\n[2022-06-21T07:19:07.136838] Removing absolute paths from host...\n[2022-06-21T07:19:07.137130] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n[2022-06-21T07:19:07.752450] Ran Sidecar release cmd.\n[2022-06-21T07:19:07.752550] Job release is complete\n\nStepRun(batch-score-taxi) Execution Summary\n============================================\nStepRun( batch-score-taxi ) Status: Failed\n\nWarnings:\n{\n  \"error\": {\n    \"code\": \"UserError\",\n    \"severity\": null,\n    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n    \"messageFormat\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n    \"messageParameters\": {\n      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n    },\n    \"referenceCode\": null,\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": {\n      \"code\": \"UserTrainingScriptFailed\",\n      \"innerError\": null\n    },\n    \"debugInfo\": null,\n    \"additionalInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"894a79b0d306da729aa9e2d47607acb7\",\n    \"request\": \"bd6aa5151035ba11\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2022-06-21T07:19:20.6318967+00:00\",\n  \"componentName\": \"globaljobdispatcher\"\n}\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(workspace\u001b[38;5;241m=\u001b[39mworkspace, steps\u001b[38;5;241m=\u001b[39m[parallelrun_step])\n\u001b[1;32m      5\u001b[0m pipeline_run \u001b[38;5;241m=\u001b[39m Experiment(workspace, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmslearn-taxi-batch\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msubmit(pipeline)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:738\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 738\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    744\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:831\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647193756013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('taxi-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='taxi-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('taxi-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "dfs = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "dfs.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "dfs.head(20)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647195426886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\r\n",
        "path =r'./batch-data'\r\n",
        "filenames = glob.glob(path + \"/*.csv\")\r\n",
        "dfall = []\r\n",
        "for csv in filenames:\r\n",
        "    frame = pd.read_csv(csv,delimiter=',', header = None)\r\n",
        "    frame['filename'] = os.path.basename(csv)\r\n",
        "    dfall.append(frame)\r\n",
        "# Concatenate all data into one DataFrame\r\n",
        "cols = list(dfb.columns)\r\n",
        "cols.append(\"file_name\")\r\n",
        "cols.remove(\"tip_amount\")\r\n",
        "big_frame = pd.concat(dfall, ignore_index=True)\r\n",
        "big_frame.columns = cols\r\n",
        "dfj = pd.concat([big_frame,dfs],axis=1, join='inner')\r\n",
        "df_final = dfj[['file_name','VendorID','PULocationID','DOLocationID','Prediction']]\r\n",
        "df_final.file_name = df_final['file_name'].apply(lambda x: x.rpartition('.')[0]).astype(int)\r\n",
        "df_final['Customer'] = df_final.file_name\r\n",
        "df_final = df_final.drop(columns = 'file_name')\r\n",
        "df_final = df_final[['Customer','VendorID','PULocationID','DOLocationID','Prediction']]\r\n",
        "df_final = df_final.sort_values(by = 'Customer')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648210051087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dft.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat(dfall).head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.reset_index(drop=True).head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648210055667
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder\r\n",
        "batch_folder = './final-data'\r\n",
        "os.makedirs(batch_folder, exist_ok=True)\r\n",
        "print(\"Folder created!\")\r\n",
        "\r\n",
        "df_final.to_csv('./final-data/final2.csv', index=False)\r\n",
        "\r\n",
        "# Upload the files to the default datastore\r\n",
        "print(\"Uploading files to datastore...\")\r\n",
        "default_ds = workspace.get_default_datastore()\r\n",
        "default_ds.upload(src_dir=\"final-data\", target_path=\"final-data\", overwrite=True, show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648210147938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfb.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "\r\n",
        "# Remove the local results folder if left over from a previous run\r\n",
        "shutil.rmtree('taxi-results', ignore_errors=True)\r\n",
        "\r\n",
        "# Get the run for the first step and download its output\r\n",
        "prediction_run = next(pipeline_run.get_children())\r\n",
        "prediction_output = prediction_run.get_output_data('inferences')\r\n",
        "prediction_output.download(local_path='taxi-results')\r\n",
        "\r\n",
        "# Traverse the folder hierarchy and find the results file\r\n",
        "for root, dirs, files in os.walk('taxi-results'):\r\n",
        "    for file in files:\r\n",
        "        if file.endswith('parallel_run_step.txt'):\r\n",
        "            result_file = os.path.join(root,file)\r\n",
        "\r\n",
        "# cleanup output format\r\n",
        "df = pd.read_csv(result_file, delimiter=\":\", header=None)\r\n",
        "df.columns = [\"File\", \"Prediction\"]\r\n",
        "\r\n",
        "# Display the first 20 results\r\n",
        "df.head(20)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1647197018006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}